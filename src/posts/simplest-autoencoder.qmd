---
title: The Simplest Autoencoder
jupyter: python3
---

blog post [@liuBackstoryBackpropagation2023].
book [@rumelhartChapter8Learning1986]

```{python}
import marimo as mo
import numpy as np
import torch
from torch import nn
from torchviz import make_dot
```

Define the inputs.

```{python}
INPUTS = torch.diag(torch.ones(8))
INPUTS
```

Define the network

```{python}
from collections import OrderedDict

class AutoEncoder(nn.Module):
    def __init__(self):
        super().__init__()
        self.stack = nn.Sequential(OrderedDict([
            ('hidden', nn.Linear(8, 3, bias=True)),
            ('output', nn.Linear(3, 8, bias=True)),
            ('sigmoid', nn.Sigmoid())
        ]))

    def forward(self, x):
        return self.stack(x)

    def encode(self, x):
        return self.stack[0](x)
```

Train it

```{python}
def train(epochs: int, lr: float, momentum: float):
    model = AutoEncoder()

    loss_fn = nn.MSELoss(reduction='mean')
    sgd = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)
    
    prev_loss = 1e9
    loss = 0
    iters = []
    losses = []
    for i in range(epochs):
        x = INPUTS
        yhat = model(x)
        prev_loss = loss
        loss = loss_fn(yhat, x)

        sgd.zero_grad()
        loss.backward()
        sgd.step()

        if i % 5000 == 0:
            print(f"i = {i}, loss: {loss:>7f}")

        iters.append(i)
        losses.append(loss.item())

    return model, iters, losses
```

Visualize the loss

```{python}
import matplotlib.pyplot as plt

torch.manual_seed(42)
net, iters, losses = train(20000, 0.1, 0.9)
plt.plot(iters, losses)
```

Outputs

```{python}
torch.set_printoptions(linewidth=120, sci_mode=False)
net(INPUTS)
```

```{python}
net.encode(INPUTS[7])
```


Things I learned while training this network:

- MSE loss doesn't work.
- Gradient descent with one example at a time doesn't work very reliably.

The point of the autoencoder is to learn two functions, the encoder and decoder.
Each of the weight matrices can be thought of as a function.

Print out the 3-element representations for each input.
Try reducing the floats to 16 bit or lower?

Can a single layer with sigmoid learn this?

Clojure

```clojure
(defn dot
  "Dot product of two vectors"
  [a b]
  (reduce + 0.0 (map * a b)))

(dot [1 2 3] [4 5 6])
;;=> 32.0
```
