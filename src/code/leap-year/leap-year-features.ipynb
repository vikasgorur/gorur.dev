{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_leap_year(y: int) -> bool:\n",
    "    if y % 400 == 0:\n",
    "        return True\n",
    "    if y % 100 == 0:\n",
    "        return False\n",
    "    return y % 4 == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDic\n",
    "from torch import nn\n",
    "\n",
    "class LeapNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.stack = nn.Sequential(OrderedDict([\n",
    "            ('hidden', nn.Linear(3, 4)),     # Single hidden layer\n",
    "            ('relu', nn.ReLU()),\n",
    "            ('output', nn.Linear(4, 1)),\n",
    "            ('sigmoid', nn.Sigmoid())\n",
    "        ]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.stack(x)\n",
    "\n",
    "    def encode_year(year: int) -> torch.Tensor:\n",
    "        # We are ok with years 0-65535 (16-bit)\n",
    "        assert(0 <= year <= 65535)\n",
    "        return torch.tensor([\n",
    "            float(year % 4 == 0),    # divisible by 4\n",
    "            float(year % 100 == 0),  # divisible by 100\n",
    "            float(year % 400 == 0)   # divisible by 400\n",
    "        ], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(model_class: nn.Module) -> tuple[nn.Module, torch.Tensor]:\n",
    "    # Create training data for all possible years\n",
    "    years = torch.arange(0, 65536)\n",
    "    X = torch.stack([model_class.encode_year(int(y)) for y in years])\n",
    "    y = torch.tensor([float(is_leap_year(int(y))) for y in years], dtype=torch.float32).reshape(-1, 1)\n",
    "    \n",
    "    # Initialize model and optimizer\n",
    "    model = model_class()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.05)\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    # Train for 100 epochs\n",
    "    for epoch in range(100):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X)\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch {epoch+1}, Loss: {loss.item():.6f}')\n",
    "    \n",
    "    # Get predictions for all inputs\n",
    "    with torch.no_grad():\n",
    "        all_predictions = model(X)\n",
    "    \n",
    "    return model, all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(model_class):\n",
    "    # Train the model and get predictions\n",
    "    model, predictions = train_and_validate(model_class)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    years = torch.arange(0, 65536)\n",
    "    true_labels = torch.tensor([float(is_leap_year(int(y))) for y in years], dtype=torch.float32).reshape(-1, 1)\n",
    "    predicted_labels = (predictions >= 0.5).float()\n",
    "    accuracy = (predicted_labels == true_labels).float().mean()\n",
    "\n",
    "    print(f\"Overall accuracy: {accuracy.item():.6f}\")\n",
    "\n",
    "    # Show some example predictions\n",
    "    print(\"\\nSample predictions (year: true -> predicted):\")\n",
    "    for year in [2020, 2021, 2000, 1900, 2100]:\n",
    "        with torch.no_grad():\n",
    "            pred = model(model_class.encode_year(year))\n",
    "        print(f\"{year}: {is_leap_year(year)} -> {pred.item():.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.683772\n",
      "Epoch 20, Loss: 0.606247\n",
      "Epoch 30, Loss: 0.508997\n",
      "Epoch 40, Loss: 0.402763\n",
      "Epoch 50, Loss: 0.303671\n",
      "Epoch 60, Loss: 0.219485\n",
      "Epoch 70, Loss: 0.155203\n",
      "Epoch 80, Loss: 0.110464\n",
      "Epoch 90, Loss: 0.080003\n",
      "Epoch 100, Loss: 0.059809\n",
      "Overall accuracy: 1.000000\n",
      "\n",
      "Sample predictions (year: true -> predicted):\n",
      "2020: True -> 0.933937\n",
      "2021: False -> 0.052544\n",
      "2000: True -> 0.918699\n",
      "1900: False -> 0.137901\n",
      "2100: False -> 0.137901\n"
     ]
    }
   ],
   "source": [
    "run_experiment(LeapNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from torch import nn\n",
    "\n",
    "class LeapNet2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.stack = nn.Sequential(OrderedDict([\n",
    "            ('hidden', nn.Linear(3, 12)),     # Single hidden layer\n",
    "            ('relu', nn.ReLU()),\n",
    "            ('output', nn.Linear(12, 1)),\n",
    "            ('sigmoid', nn.Sigmoid())\n",
    "        ]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.stack(x)\n",
    "\n",
    "    def encode_year(year: int) -> torch.Tensor:\n",
    "        # We are ok with years 0-65535 (16-bit)\n",
    "        assert(0 <= year <= 65535)\n",
    "        return torch.tensor([year, year, year], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 24.223743\n",
      "Epoch 20, Loss: 24.218676\n",
      "Epoch 30, Loss: 24.166487\n",
      "Epoch 40, Loss: 24.208176\n",
      "Epoch 50, Loss: 24.226738\n",
      "Epoch 60, Loss: 24.230324\n",
      "Epoch 70, Loss: 24.231634\n",
      "Epoch 80, Loss: 24.231955\n",
      "Epoch 90, Loss: 24.232063\n",
      "Epoch 100, Loss: 24.232092\n",
      "Overall accuracy: 0.757523\n",
      "\n",
      "Sample predictions (year: true -> predicted):\n",
      "2020: True -> 0.000000\n",
      "2021: False -> 0.000000\n",
      "2000: True -> 0.000000\n",
      "1900: False -> 0.000000\n",
      "2100: False -> 0.000000\n"
     ]
    }
   ],
   "source": [
    "run_experiment(LeapNet2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
